#### 基于机器学习的文本分类！
文本分类一般有两种处理思路：基于机器学习的方法和基于深度学习的方法。
本文主要基于机器学习的方法，介绍了特征提取+分类模型在文本分类中的应用。具体目录如下
Contents
- 数据以及背景
- 数据为藏文数据，来自西藏人民网站，两种类型，分别为新闻和文化，具体个数如下：
མི་དམངས་ དྲ་བ འི་ འཕྲིན། ཟླ་ 12 ཚེས་ 14 ནས་ ཚེས་ 15 ཉིན་ བར། སི་ཁྲོན་ ཞིང་ཆེན་ དཀར་མཛེས་ བོད་རིགས་ རང་སྐྱོང་ཁུལ་ ཨུ་དང་ཁུལ་ སྲིད་གཞུང་ གིས་ གཙོ་གཉེར་བྱས་ ཤིང་ །ཁུལ་ ཨུའི་ དྲིལ་བསྒྲགས་པུའུ་ དང་ ཁུལ་ རིག་གནས་ ལུས་རྩལ་ རྒྱང་བསྒྲགས་ གསར་འགྱུར་ དཔེ་སྐྲུན་ ཅུས།ཁུལ་ བོད་ཡིག་ ཡིག་གཟུགས་ མཐུན་ཚོགས་ བཅས་ ཀྱིས་ སྒྲུབ་འགན་ཁུར་བ འི་ དཀར་མཛེས་ཁུལ་ གྱི་ སྐབས་ དང་པོ འི་ བོད་ཡིག་ ཡིག་གཟུགས་ འགྲན་བསྡུར་ ཆེན་མོ་ དེ་ དུང་དཀར་ ལུང་པ ར་ སྤེལ་ བ་ རེད།，文化
- 文本表示
- 在机器学习算法的训练过程中，假设给定N个样本，每个样本有M个特征，这样就组成了NxM的样本矩阵。在计算机视觉中可以把图片的像素看作特征，每张图片都可以视为的特征图，然后用一个三维矩阵带入计算。但是在自然语言领域，上述方法却不可行，因为文本的长度是不固定的。文本分类的第一步就是将不定长的文本转换到定长的空间内，即词嵌入
- One-Hot
One-hot方法将每一个单词使用一个离散的向量表示，将每个字/词编码成一个索引，然后根据索引进行赋值。
- Bags of Words
Bags of Words，也称为Count Vectors，每个文档的字/词可以使用其出现次数来进行表示
- N-gram
N-gram与Count Vectors类似，不过加入了相邻单词组合为新的单词，并进行计数。
- TF-IDF
TF-IDF分数由两部分组成：第一部分是词语频率(Term Frequency)，第二部分是逆文档频率(Inverse Document Frequency)
- 基于机器学习的文本分类
接下来我们将研究文本表示对算法精度的影响，对比同一分类算法在不同文本表示下的算法精度，通过本地构建验证集计算F1得分
- 导入相关的包
- 读取数据
- 文本分类对比
- 研究参数对模型的影响
- 正则化参数对模型的影响
可以看出a不宜取的过大，也不宜过小。a越小模型的拟合能力越强，泛化能力越弱，a越大模型的拟合能力越差，泛化能力越强。
- max_features对模型的影响
可以看出max_features越大模型的精度越高，但是当max_features超过某个数之后，再增加max_features的值对模型精度的影响就不是很显著了。
- ngram_range对模型的影响
- 考虑其他分类模型
- LogisticRegression
- SGDClassifier
- SVM
总结：对比几种机器学习算法可以看出，在相同的TF-IDF特征提取方法基础上，用SVM得到的分类效果最好
 
